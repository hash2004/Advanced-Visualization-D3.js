{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Certificates  \n",
    "SSLCertVerificationError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install certifi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downlaoding the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to /Users/wajeeh/.convokit/downloads/movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n",
      "No configuration file found at /Users/wajeeh/.convokit/config.yml; writing with contents: \n",
      "# Default Backend Parameters\n",
      "db_host: localhost:27017\n",
      "data_directory: ~/.convokit/saved-corpora\n",
      "default_backend: mem\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 9035\n",
      "Number of Utterances: 304713\n",
      "Number of Conversations: 83097\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They do not!\n",
      "They do to!\n",
      "I hope so.\n",
      "She okay?\n",
      "Let's go.\n",
      "Wow\n",
      "Okay -- you're gonna need to learn how to lie.\n",
      "No\n",
      "I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "Like my fear of wearing pastels?\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 utterances\n",
    "for utterance in list(corpus.iter_utterances())[:10]:\n",
    "    print(utterance.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvoKitMeta({'character_name': 'BIANCA', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'f', 'credit_pos': '4'})\n",
      "ConvoKitMeta({'character_name': 'CAMERON', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'm', 'credit_pos': '3'})\n",
      "ConvoKitMeta({'character_name': 'CHASTITY', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': '?', 'credit_pos': '?'})\n",
      "ConvoKitMeta({'character_name': 'JOEY', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'm', 'credit_pos': '6'})\n",
      "ConvoKitMeta({'character_name': 'KAT', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'f', 'credit_pos': '2'})\n",
      "ConvoKitMeta({'character_name': 'WALTER', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'm', 'credit_pos': '9'})\n",
      "ConvoKitMeta({'character_name': 'BRUCE', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': '?', 'credit_pos': '?'})\n",
      "ConvoKitMeta({'character_name': 'PATRICK', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'm', 'credit_pos': '1'})\n",
      "ConvoKitMeta({'character_name': 'MICHAEL', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'm', 'credit_pos': '5'})\n",
      "ConvoKitMeta({'character_name': 'MANDELLA', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'f', 'credit_pos': '7'})\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 speakers\n",
    "for speaker in list(corpus.iter_speakers())[:10]:\n",
    "    print(speaker.meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L1045', 'L1044']\n",
      "['L985', 'L984']\n",
      "['L925', 'L924']\n",
      "['L872', 'L871', 'L870']\n",
      "['L869', 'L868', 'L867', 'L866']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 conversations\n",
    "for convo in list(corpus.iter_conversations())[:5]:\n",
    "    print(convo.get_utterance_ids())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [utterance.text for utterance in corpus.iter_utterances()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BERT for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bdf83af08d4b6bae518aa5136befad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ac07e946f847dca01711a65ab712e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2069b4e52d49404ab2a30bbf0fb85263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4489960661754b29a0ac35e15579450e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
    "model = BertForTokenClassification.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform NER with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: They do not!\n",
      "Entities: [('[CLS]', 'O'), ('They', 'O'), ('do', 'O'), ('not', 'O'), ('!', 'O'), ('[SEP]', 'O')]\n",
      "Text: They do to!\n",
      "Entities: [('[CLS]', 'O'), ('They', 'O'), ('do', 'O'), ('to', 'O'), ('!', 'O'), ('[SEP]', 'O')]\n",
      "Text: I hope so.\n",
      "Entities: [('[CLS]', 'O'), ('I', 'O'), ('hope', 'O'), ('so', 'O'), ('.', 'O'), ('[SEP]', 'O')]\n",
      "Text: She okay?\n",
      "Entities: [('[CLS]', 'O'), ('She', 'O'), ('okay', 'O'), ('?', 'O'), ('[SEP]', 'O')]\n",
      "Text: Let's go.\n",
      "Entities: [('[CLS]', 'O'), ('Let', 'O'), (\"'\", 'O'), ('s', 'O'), ('go', 'O'), ('.', 'O'), ('[SEP]', 'O')]\n",
      "Text: Wow\n",
      "Entities: [('[CLS]', 'O'), ('Wow', 'O'), ('[SEP]', 'O')]\n",
      "Text: Okay -- you're gonna need to learn how to lie.\n",
      "Entities: [('[CLS]', 'O'), ('Okay', 'O'), ('-', 'O'), ('-', 'O'), ('you', 'O'), (\"'\", 'O'), ('re', 'O'), ('gonna', 'O'), ('need', 'O'), ('to', 'O'), ('learn', 'O'), ('how', 'O'), ('to', 'O'), ('lie', 'O'), ('.', 'O'), ('[SEP]', 'O')]\n",
      "Text: No\n",
      "Entities: [('[CLS]', 'O'), ('No', 'O'), ('[SEP]', 'O')]\n",
      "Text: I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "Entities: [('[CLS]', 'O'), ('I', 'O'), (\"'\", 'O'), ('m', 'O'), ('kidding', 'O'), ('.', 'O'), ('You', 'O'), ('know', 'O'), ('how', 'O'), ('sometimes', 'O'), ('you', 'O'), ('just', 'O'), ('become', 'O'), ('this', 'O'), ('\"', 'O'), ('persona', 'O'), ('\"', 'O'), ('?', 'O'), ('And', 'O'), ('you', 'O'), ('don', 'O'), (\"'\", 'O'), ('t', 'O'), ('know', 'O'), ('how', 'O'), ('to', 'O'), ('quit', 'O'), ('?', 'O'), ('[SEP]', 'O')]\n",
      "Text: Like my fear of wearing pastels?\n",
      "Entities: [('[CLS]', 'O'), ('Like', 'O'), ('my', 'O'), ('fear', 'O'), ('of', 'O'), ('wearing', 'O'), ('paste', 'O'), ('##ls', 'O'), ('?', 'O'), ('[SEP]', 'O')]\n"
     ]
    }
   ],
   "source": [
    "def bert_ner(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs).logits\n",
    "    predictions = softmax(outputs, dim=2)\n",
    "    entities = [tokenizer.convert_ids_to_tokens(input_id) for input_id in inputs['input_ids'].tolist()]\n",
    "\n",
    "    return [(word, model.config.id2label[pred.argmax().item()]) for word, pred in zip(entities[0], predictions[0])]\n",
    "\n",
    "# Example usage\n",
    "for text in texts[:10]:  # Analyze first 10 texts\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Entities:\", bert_ner(text, tokenizer, model))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: They do not!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/wajeeh/Desktop/DAV/project/main.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wajeeh/Desktop/DAV/project/main.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m user \u001b[39m=\u001b[39m Speaker(corpus, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mspeaker_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wajeeh/Desktop/DAV/project/main.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Create an utterance\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wajeeh/Desktop/DAV/project/main.ipynb#X32sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m utterance \u001b[39m=\u001b[39m Utterance(corpus, user\u001b[39m.\u001b[39;49mid, conversation\u001b[39m.\u001b[39;49mid, text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wajeeh/Desktop/DAV/project/main.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Store NER results in the utterance's metadata\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wajeeh/Desktop/DAV/project/main.ipynb#X32sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m utterance\u001b[39m.\u001b[39mmeta[\u001b[39m'\u001b[39m\u001b[39mnamed_entities\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m entities\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/convokit/model/utterance.py:58\u001b[0m, in \u001b[0;36mUtterance.__init__\u001b[0;34m(self, owner, id, speaker, conversation_id, reply_to, timestamp, text, meta)\u001b[0m\n\u001b[1;32m     51\u001b[0m     warn(\n\u001b[1;32m     52\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUtterance text must be a string: text of utterance with ID: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhas been casted to a string.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mid\u001b[39m)\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m text \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(text)\n\u001b[1;32m     57\u001b[0m props \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mspeaker_id\u001b[39m\u001b[39m\"\u001b[39m: speaker\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconversation_id\u001b[39m\u001b[39m\"\u001b[39m: conversation_id,\n\u001b[1;32m     60\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreply_to\u001b[39m\u001b[39m\"\u001b[39m: reply_to,\n\u001b[1;32m     61\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m: timestamp,\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: text,\n\u001b[1;32m     63\u001b[0m }\n\u001b[1;32m     64\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(obj_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutterance\u001b[39m\u001b[39m\"\u001b[39m, owner\u001b[39m=\u001b[39mowner, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mid\u001b[39m, initial_data\u001b[39m=\u001b[39mprops, meta\u001b[39m=\u001b[39mmeta)\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspeaker_ \u001b[39m=\u001b[39m speaker\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "import convokit\n",
    "from convokit import Corpus, Speaker, Utterance\n",
    "\n",
    "# Initialize a ConvoKit Corpus\n",
    "corpus = Corpus()\n",
    "\n",
    "# Example usage\n",
    "for i, text in enumerate(texts[:10]):  # Analyze first 10 texts\n",
    "    print(\"Text:\", text)\n",
    "    entities = bert_ner(text, tokenizer, model)\n",
    "\n",
    "    # Create a new conversation for each text\n",
    "    conversation_id = f\"conversation_{i}\"\n",
    "    conversation = convokit.Conversation(corpus, conversation_id)\n",
    "\n",
    "    # Create a user (speaker)\n",
    "    user = Speaker(corpus, f\"user_{i}\")\n",
    "\n",
    "    # Create an utterance\n",
    "    utterance = Utterance(corpus, user.id, conversation.id, text)\n",
    "\n",
    "    # Store NER results in the utterance's metadata\n",
    "    utterance.meta['named_entities'] = entities\n",
    "\n",
    "    # Add the utterance to the conversation\n",
    "    conversation.add_utterance(utterance)\n",
    "\n",
    "    # Add the conversation to the corpus\n",
    "    corpus.add_conversation(conversation)\n",
    "\n",
    "# Save the Corpus to a file for later analysis and visualization\n",
    "corpus.dump(\"movie-corpus-with-ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
